<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[日志监控告警系统（二）]]></title>
      <url>http://spark8.tech/2016/05/18/rizhijiankong2/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<p>#基于实时日志监控业务的一些考虑<br>Q: 业务对于时效的要求，要怎样的采集方式？</p>
<blockquote>
<p>A:  实时采集不断读取各日志服务器日志</p>
</blockquote>
<p>Q: 日志数据的来源有哪些，数据量有多大？</p>
<blockquote>
<p>A:  日志来自8个业务系统(订单系统、商品系统等)，假设各系统每天产生的日志总和为1T。那么平均20M/s，晚上少流量，正常40M/s，类似双11促销峰值10倍400M/s,不考虑未来有可能数据增加到10T，仅以当下数据量来说。设计目标是使用大量低速高容量的硬盘短时间内存储更多的数据。而单机硬盘默认2T，增加2T硬盘使得每个机器达到4T。1T的数据保存5天，备份一份，就是10T空间，基本上3台机器可以满足。<br>就经验上来说，对于小于10T的数据量，3台4T的机器足以，不要过度设计和考虑容量问题，毕竟日志的存储天数可以调的，要考虑成本。</p>
</blockquote>
<p>Q：如何实现对日志的清洗、过滤处理？</p>
<blockquote>
<p>A：日志来自8个系统的日志，存储在专门的日志服务器集群中，每个系统都有一个flume的agent，source中添加拦截器，区分来自各个系统的aped，然后sink到kafka集群。LogMonitorTopology通过于flume sink相同的zk配置从Kafka-spout获取外部数据源。FileterBolt调用message.parse方法对消息进行合法性检验，<br><img src="/images/messageparse.png" alt="" title="messageparse"></p>
</blockquote>
<p>Q：过滤后的数据是为了实现怎样的业务目的，要匹配怎样的处理规则？</p>
<blockquote>
<p>A：根据各个appid得知此消息属于哪个业务系统，从mysq中取出该系统对应的ruleList缓存至worker进程，用消息去匹配规则列表，匹配成功则向该系统管理员发送邮件或者短信。而为什么在worker进程里面都保存一份而不是存redis全局共享一份，是因为每个进程内都条记录处理都需要pull一次，有大量的进程间通信，消耗性能。<br><img src="/images/messagetrigger.png" alt="" title="messagetrigger"></p>
</blockquote>
<p>Q：错误信息经常是好几条日志信息一起出现的，怎么解决重复发送邮件的问题？</p>
<blockquote>
<p>A:  业务就是为了保证不重复发送邮件通知，基于业务本身，将appid+触发的ruleid生成唯一的key存入redis，每次发送消息前先去redis中检查，因为只有极少的日志携带规则的信息，所以此处用redis没问题。<br><img src="/images/messageexe.png" alt="" title="messagecf"></p>
</blockquote>
<p>Q:  集群模式下如何保证数据匹配的规则的数据一致性？</p>
<blockquote>
<p>A:  程序启动时初始化规则列表，并采用定时更新规则数据的策略，但定时任务在运行时必涉及线程安全（如2个worker进程，10个Bolt的并行度，则每个worker中必有5个bolt task运行）通过加锁和开关实现线程安全控制。<br><img src="/images/messagebxd.png" alt="规则线程安全图" title="messagebxd"><br><img src="/images/messagekgs.png" alt="" title="messagekgs"></p>
</blockquote>
<p>Q：最后，在实现了各个环节的功能后，如何优化整体性能？</p>
<blockquote>
<p>A：整个实时日志监控项目的后台部分由flume+kafka+storm+redis+mysql组成。其中性能优化的组件主要在flume、kafka和storm。<br>第一是规范数据来源，此处应用到flume日志采集时自定义拦截器，使得日志在采集阶段即已分类，方便storm的数据处理。<br>第二是提高数据吞吐量，此处关键是kafka分片数的确定，决定分片数的主要因素是数据量，理论上kafka吞吐数据能达到600M/S，我们以300M/S来计算，10T数据需要14个分片，这也间接的决定了storm分配的spout并行度为14个。<br>第三是数据处理效率，在前面已经优化的基础上，storm处理的复杂度已大为降低，同一Topology内设置spout数等于kafka分片数，经过aped分组后，将目的bolt按字段分组(field grouping或者localorfieldgrouping)，并将bolt的executor数量设置为分组数的倍数。同一worker内 读取规则库用本地缓存减少了进程间通信次数可能带来的延迟。通过这两个措施即可提高storm的处理效率。</p>
</blockquote>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[日志监控告警系统（一）]]></title>
      <url>http://spark8.tech/2016/05/17/rizhijiankong1/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>随着公司业务发展，支撑公司业务的各种系统越来越多，为了保证公司的业务正常发展，急需要对这些线上系统的运行进行监控，做到问题的及时发现和处理，最大程度减少对业务的影响。<br>目前系统分类有：<br>1)    有基于Tomcat的web应用<br>2)    有独立的Java Application应用<br>3)    有运行在linux上的脚本程序<br>4)    有大规模的集群框架（zookeeper、Hadoop、Storm…）<br>5)    有操作系统的运行日志<br>主要功能需求分为：<br>监控系统日志中的内容，按照一定规则进行过滤<br>发现问题之后通过短信和邮件进行告警</p>
<h2 id="功能分析"><a href="#功能分析" class="headerlink" title="功能分析"></a>功能分析</h2><p>数据输入<br>使用flume客户端获取个系统的数据；<br>用户通过页面输入系统名称、负责人触发规则等信息<br>数据存储<br>使用flume采集数据并存放在kafka集群中<br>数据计算<br>使用storm编写程序对日志进行过滤，将满足过滤规则的信息，通过邮件短信告警并保存到数据库中<br>数据展示<br>管理页面可以查看触发规则的信息，系统负责人，联系方式，触发信息明细等</p>
<h2 id="原型设计"><a href="#原型设计" class="headerlink" title="原型设计"></a>原型设计</h2><p>产品经理设计原型</p>
<h1 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h1><h3 id="整体架构设计"><a href="#整体架构设计" class="headerlink" title="整体架构设计"></a>整体架构设计</h3><p><img src="/images/DraggedImage.png" alt="整体架构"><br><img src="/images/ztlc.png" alt="整体流程图" title="整体流程图"><br>主要架构为应用+flume+kafka+storm+mysql+Java web。数据流程如下：</p>
<ol>
<li>应用程序使用log4j产生日志</li>
<li>部署flume客户端监控应用程序产生的日志信息，并发送到kafka集群中</li>
<li>storm spout拉去kafka的数据进行消费，逐条过滤每条日志的进行规则判断，对符合规则的日志进行邮件告警。</li>
<li>最后将告警的信息保存到mysql数据库中，用来进行管理。<h3 id="Flume设计"><a href="#Flume设计" class="headerlink" title="Flume设计"></a>Flume设计</h3>Flume说明<br>Flume是一个分布式、可靠地、可用的服务，用来收集、聚合、传输日志数据。<br>它是一个基于流式数据的架构，简单而灵活。具有健壮性、容错机制、故障转移、恢复机制。<br>它提供一个简单的可扩展的数据模型，容许在线分析程序。F<br>Flume 作为 cloudera 开发的实时日志收集系统，受到了业界的认可与广泛应用。<br>Flume 设计摘要<br>使用 Flume EXEC执行一个linux命令来生成数据源。例如，可以用tail命令监控一个文件，那么，只要文件增加内容，EXEC就可以将增加的内容作为数据源发送出去。<br>使用 org.apache.flume.plugins.KafkaSink，将Flume EXEC产生的数据源发送到Kafka中。<h3 id="Kafka设计"><a href="#Kafka设计" class="headerlink" title="Kafka设计"></a>Kafka设计</h3>Kafka说明<br>kafka是一个分布式消息队列：生产者、消费者的功能。<br>Kakfa设计摘要<br>部署kafka集群，在集群中添加一个Topic：monitor_realtime_javaxy<h3 id="Storm设计"><a href="#Storm设计" class="headerlink" title="Storm设计"></a>Storm设计</h3>KafkaSpout读取数据，需要配置Topic：monitor_realtime_javaxy<br>FilterBolt判断规则<br>NotifyBolt用来发送邮件或短信息<br>Save2DB用来将告警信息写入mysql数据库<h3 id="数据模型设计"><a href="#数据模型设计" class="headerlink" title="数据模型设计"></a>数据模型设计</h3><h4 id="用户表"><a href="#用户表" class="headerlink" title="用户表"></a>用户表</h4>用来保存用户的信息，包括账号、手机号码、邮箱、是否有效等信息。各字段请参加<a href="github">github</a>具体bean(comment截屏不便)<br><img src="/images/log_monitor_user.png" alt="log_monitor_user" title="log_monitor_user"><h4 id="应用表"><a href="#应用表" class="headerlink" title="应用表"></a>应用表</h4>用来保存应用的信息，包括应用名称、应用描述、应用是否在线等信息。<br><img src="/images/log_monitor_app.png" alt="log_monitor_app" title="log_monitor_app"><h4 id="应用类型表"><a href="#应用类型表" class="headerlink" title="应用类型表"></a>应用类型表</h4>用来保存应用的类型等信息。<br><img src="/images/log_monitor_app_type.png" alt="log_monitor_app\_type" title="log_monitor_app_type"><h4 id="规则表"><a href="#规则表" class="headerlink" title="规则表"></a>规则表</h4>用来保存规则的信息，包括规则名称，规则描述，规则关键词等信息。<br><img src="/images/log_monitor_rule.png" alt="log_monitor_rule" title="log_monitor_rule"><h4 id="规则记录表"><a href="#规则记录表" class="headerlink" title="规则记录表"></a>规则记录表</h4>用来保存触发规则后的记录，包括告警编号、是否短信告知、是否邮件告知、告警明细等信息。<br><img src="/images/log_monitor_rule_record.png" alt="log_monitor_rule_record" title="log_monitor_rule_record"><h2 id="代码开发"><a href="#代码开发" class="headerlink" title="代码开发"></a>代码开发</h2><h3 id="工程结构"><a href="#工程结构" class="headerlink" title="工程结构"></a>工程结构</h3><img src="/images/ssgc.png" alt="工程结构" title="工程结构"><h4 id="LogMonitorTopologyMain驱动类"><a href="#LogMonitorTopologyMain驱动类" class="headerlink" title="LogMonitorTopologyMain驱动类"></a>LogMonitorTopologyMain驱动类</h4><img src="/images/logmtm.png" alt=""><h4 id="KafkaSpout获取数据源"><a href="#KafkaSpout获取数据源" class="headerlink" title="KafkaSpout获取数据源"></a>KafkaSpout获取数据源</h4><img src="/images/kafkasp.png" alt=""><h4 id="FilterBolt过滤日志信息"><a href="#FilterBolt过滤日志信息" class="headerlink" title="FilterBolt过滤日志信息"></a>FilterBolt过滤日志信息</h4><img src="/images/filb.png" alt=""><h4 id="PrepareRecordBolt发送邮件告警和短信告警"><a href="#PrepareRecordBolt发送邮件告警和短信告警" class="headerlink" title="PrepareRecordBolt发送邮件告警和短信告警"></a>PrepareRecordBolt发送邮件告警和短信告警</h4><img src="/images/prep.png" alt=""><h4 id="SaveMessage2MySq保存到数据库"><a href="#SaveMessage2MySq保存到数据库" class="headerlink" title="SaveMessage2MySq保存到数据库"></a>SaveMessage2MySq保存到数据库</h4><img src="/images/s2m.png" alt=""></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Shell编程——使用HDFS Shell上传文件]]></title>
      <url>http://spark8.tech/2016/05/17/shelltohdfs/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><p>点击流日志每天都10G，需要上传数据仓库（Hadoop HDFS）上</p>
<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>一般上传文件都是在凌晨24点操作，由于很多种类的业务数据都要在晚上进行传输，为了减轻服务器的压力，避开高峰期。需要伪实时的上传，即当文件有10G的时候，就上传一个。<br>一、    正常上传到hdfs的需求</p>
<ol>
<li>上传到hdfs的文件需要校验完整性。MD5</li>
<li>一个文件在上传过程中另一个进程不能再次上传该文件  <em>COPY</em></li>
<li>上传到hdfs的文件名不能相同   时间戳</li>
<li>定时上传文件到hdfs  PUT<br>二、    异常上传的需求</li>
<li><p>文件上传到hdfs过程中失败，需要有重试机制，<br> 若能再次连上需要保证数据能再次上传且数据不重复，也不丢失，<br> HDFS文件列表和本地待上传的文件列表进行比对<br> grep -diff<br> 若超过重试限制后需要发短信通知<br> java -jar </p>
</li>
<li><p>ftp服务连不上，需要有重试机制，超过重试限制需要发短信通知</p>
</li>
<li>运行脚本的服务器挂了，需要有备份服务器启动，并发短信通知<h2 id="实现流程"><a href="#实现流程" class="headerlink" title="实现流程"></a>实现流程</h2><h3 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h3></li>
<li>HDFS SHELL:  hadoop fs  –put   xxxx.tar  /data    还可以使用 Java Api<br>  满足上传一个文件，不能满足定时、周期性传入。</li>
<li><p>Linux crontab<br>“crontab -e <em>/5 </em> <em> </em> * $home/bin/command.sh ” //五分钟执行一次<br>系统会自动执行脚本，每五分钟一次，执行时判断文件是否等于10G，如果等于10G就可以上传。</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>以下为正常上传部分代码，异常上传部分未实现，只提供如上思路</p>
<pre><code>!/bin/bash
set java env
export JAVA_HOME=/export/servers/jdk
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH

set hadoop env
export HADOOP_HOME=/export/servers/hadoop
export PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH
</code></pre><p>日志文件存放的目录</p>
<pre><code>log_src_dir=/export/software/

s=du -k $log_src_dir |awk &apos;{print $1}&apos;
if [ $s -lt 1024000000 ]
then
exit 1
else
continue
fi
</code></pre><p>待上传文件存放的目录</p>
<pre><code>log_appending_dir=/export/data/click_log/
</code></pre><p>日志文件上传到hdfs的根路径</p>
<pre><code>hdfs_root_dir=/data/clickLog/20151226/
</code></pre><p>读取日志文件的目录，判断是否有需要上传的文件</p>
<pre><code>ls $log_src_dir | while read fileName
do
if [ &quot;hadoop.log1&quot; = &quot;$fileName&quot; ];then
date=date +%Y_%m_%d_%H_%M_%S
mv $log_src_dir$fileName $log_appending_dir&quot;xxxxx_click_log_&quot;$date
echo $log_appending_dir&quot;xxxxx_click_log_&quot;$date &gt;&gt; /export/data/click_log/willDoing.$date
fi

done
</code></pre><p>过滤掉正在copy和已经copy的文件</p>
<pre><code>ls $log_appending_dir | grep will |grep -v &quot;_COPY_&quot; | grep -v &quot;_DONE_&quot; | while read line
do
</code></pre><p>对拿到的文件重命名</p>
<pre><code>mv $log_appending_dir$line $log_appending_dir$line&quot;_COPY_&quot;
cat $log_appending_dir$line&quot;_COPY_&quot; |while read line
do
hadoop fs -put $line $hdfs_root_dir
done    
mv $log_appending_dir$line&quot;_COPY_&quot;  $log_appending_dir$line&quot;_DONE_&quot;
done
</code></pre><p>重试核心代码</p>
<pre><code>function failOver(){
    echo &quot;重试机制启动....&quot;
    #转钟逻辑处理
    if [ &quot;00:00&quot; = $tag ] || [ &quot;00:01&quot; = $tag ]
    then
    yesterday_dt=date --date=&apos;yesterday&apos; +%Y-%m-%d
    yesterday_ftp_date=date --date=&apos;yesterday&apos; +%Y%m%d
    put_local_file_to_hdfs $yesterday_dt $yesterday_ftp_date
    fi
    #半小时逻辑处理
    if [ &quot;40&quot; = $tagM ] || [ &quot;41&quot; = $tagM ]
    then
            today_dt=date +%Y-%m-%d
            today_ftp_date=date +%Y%m%d
            put_local_file_to_hdfs $today_dt $today_ftp_date
    fi
    echo &quot;重试机制执行完毕...&quot;
}

function put_local_file_to_hdfs(){
</code></pre></li>
</ol>
<pre><code>    diffFile=$log_dir&quot;differ_file&quot;$executeTime.log
    hdfs_file_list=$log_dir&quot;hdfs_file_list&quot;$executeTime.log
    local_file_list=$log_dir&quot;local_file_list&quot;$executeTime.log

    hadoop fs -ls /apps/hive/warehouse/stage.db/$hdfs_table/dt=$1/ | awk &apos;{print $8}&apos;|while read line
    do
            file_name=${line##*/}
            suffix=${file_name##*.}
            #如果文件正在上传中，视为已经上传成功
            if [ &quot;_COPYING_&quot; = &quot;$suffix&quot; ]
            then
                    echo &quot;此文件正在上传：&quot;$line
                    file_name=${file_name%.*}
            fi
            echo $file_name &gt;&gt; $hdfs_file_list
    done

    ls $tmp_Dir$2 |grep $file_prefix &gt;$local_file_list

    grep -vxFf $hdfs_file_list $local_file_list &gt; $diffFile

    rm $hdfs_file_list
    rm $local_file_list

    file_size=cat $diffFile |wc -l
    echo &quot;当前重试的文件个数：&quot;$file_size
    if (( &quot;$file_size&quot; &gt;= &quot;1&quot; ))
    then
            #如果重试的文件大于，触发短信告警信息
            #source ~/.base_profile
            /soft/java/bin/java -jar /export/server/real_platform/sendmsg/sendmsg.jar &quot;15652306418,18211153576&quot; $hostname&quot;机器下有 &quot;$file_size&quot; 个文件正在重试上传，小偷程序遇到问题了，请查看！&quot;
            echo &quot;发送短信成功！&quot;
    fi

    if [ -f $diffFile ]
    then 
            cat $diffFile |while read line
                            do
                            tarFile=$tmp_Dir$2&quot;/&quot;$line
                            echo &quot;开始上传文件：&quot;$tarFile
                            echo &quot;hadoop命令：hadoop fs -put &quot;$tarFile &quot;/apps/hive/warehouse/stage.db/&quot;$hdfs_table&quot;/dt=&quot;$1&quot;/&quot;
                            hadoop fs -put $tarFile /apps/hive/warehouse/stage.db/$hdfs_table/dt=$1/
                            echo &quot;上传文件结束：&quot;$tarFile
                            done
            rm $diffFile 
    fi
}
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Linux——网络连接三种方式]]></title>
      <url>http://spark8.tech/2016/05/16/Linuxline/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="一、NAT"><a href="#一、NAT" class="headerlink" title="一、NAT"></a>一、NAT</h2><p><img src="/images/NAT.png" alt="NAT示意图" title="NAT连接"></p>
<h2 id="二、bridge"><a href="#二、bridge" class="headerlink" title="二、bridge"></a>二、bridge</h2><p><img src="/images/bridge.png" alt="bridge示意图"></p>
<h2 id="三、host-only"><a href="#三、host-only" class="headerlink" title="三、host-only"></a>三、host-only</h2><p><img src="/images/host-only.png" alt="host-only示意图" title="host-only"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Shell编程——自动化软件部署脚本]]></title>
      <url>http://spark8.tech/2016/05/15/shellautodeploy/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><p>开发一个脚本，实现对局域网中的N台节点批量自动下载、安装jdk</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>编写一个启动脚本，发送一个软件安装脚本到每一台机器<br>然后启动每台机器上的软件安装脚本来执行软件下载和安装<br><img src="/images/自动化软件部署脚本思路图.png" alt="自动化软件部署脚本思路图" title="自动化软件部署脚本思路图"></p>
<h2 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h2><p>难点：使用scp命令远程拷贝文件时，会有人机交互的过程，如何让脚本完成人机交互?<br>解决：expect<br>用法示例：先观察  ssh localhost 的过程，再看expect的功能</p>
<pre><code>#!/bin/bash/expect
   # exp_test.sh
   set timeout -1;
   spawn ssh localhost;
   expect {
       &quot;(yes/no)&quot; {send &quot;yes\r&quot;;exp_continue;}
       &quot;password:&quot; {send &quot;hadoop\r&quot;;exp_continue;}
       eof        {exit 0;}
   }
</code></pre><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>选择一台服务器（比如CentOS）作为软件源服务器</p>
<ol>
<li>安装httpd</li>
<li>制作局域网yum源</li>
<li>编写repo配置</li>
<li>分发repo配置到局域网</li>
<li>准备一个jdk安装包放在内网web服务器上</li>
</ol>
<h2 id="脚本开发"><a href="#脚本开发" class="headerlink" title="脚本开发"></a>脚本开发</h2><ol>
<li><p>启动脚本boot.sh</p>
<pre><code>#!/bin/bash  
SERVERS=&quot;mini3&quot; 
PASSWORD=hadoop 
BASE_SERVER=192.168.59.101 
auto_ssh_copy_id() { 
    expect -c &quot;set timeout -1;
    spawn ssh-copy-id $1;
    expect {
        *(yes/no)* {send -- yes\r;exp_continue;}
        *assword:* {send -- $2\r;exp_continue;}
        eof{exit 0;}
    }&quot;;
}
ssh_copy_id_to_all() {
    for SERVER in $SERVERS
        do
        auto_ssh_copy_id $SERVER $PASSWORD
        done
    }
ssh_copy_id_to_all 
</code></pre></li>
<li><p>执行脚本install.sh</p>
<pre><code>#!/bin/bash
BASE_SERVER=192.168.59.101

yum install -y wget

wget $BASE_SERVER/soft/jdk-7u67-linux-x64.gz

tar -zxvf jdk-7u67-linux-x64.gz -C /usr/local

cat &gt;&gt; /etc/profile &lt;&lt; EOF
export JAVA_HOME=/usr/local/jdk1.7.0_67
export PATH=\$PATH:\$JAVA_HOME/bin
EOF
</code></pre><p> source /etc/profile</p>
</li>
<li><p>执行脚本</p>
</li>
</ol>
<p>只要在baseServer即mini上启动boot.sh即可</p>
<h2 id="通用问题"><a href="#通用问题" class="headerlink" title="通用问题"></a>通用问题</h2><p>Q1.目标机器名需要写死在脚本中<br>Tips：可以将所有需要安装软件的机器名写在一个文件：比如slaves中让脚本自动读取slaves文件中的机器名来批量安装</p>
<pre><code>cat slaves | while read host
do
echo $host
expect -c &quot;set timeout -f
spawn ssh-copy-id $host&quot;
done
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[轻量级RPC框架（二）]]></title>
      <url>http://spark8.tech/2016/05/12/easyrpc2/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><p>此RPC用于Action远程调用Service，用到的技术点包括NIO通信+序列化+反射(Spring)+动态代理(Proxy类)+Zookeeper<br>设计思路如下图：<br><img src="/images/RPC%E6%A1%86%E6%9E%B6.png" alt="RPC框架" title="RPC框架"></p>
<h2 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h2><p>工程目录如下：<br><img src="/images/%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95.png" alt="工程目录" title="工程目录"><br>具体实现及项目间依赖请参见<a href="www.baidu.com">github链接</a>，此处只做各模块功能说明</p>
<h3 id="rpc-服务端"><a href="#rpc-服务端" class="headerlink" title="rpc-服务端"></a>rpc-服务端</h3><h4 id="1-rpc-sample-server模块"><a href="#1-rpc-sample-server模块" class="headerlink" title="1.  rpc-sample-server模块"></a>1.  rpc-sample-server模块</h4><p> HelloServiceImpl</p>
<blockquote>
<p>接口的实现类<br> RpcBootstrap<br>用户系统服务端的启动入口其意义是启动springcontext，从而构造框架中的RpcServer<br>亦即：将用户系统中所有标注了RpcService注解的业务发布到RpcServer中</p>
<h4 id="2-rpc-server模块"><a href="#2-rpc-server模块" class="headerlink" title="2.   rpc-server模块"></a>2.   rpc-server模块</h4><p> RpcHandler<br>处理具体的业务调用<br>通过构造时传入的“业务接口及实现”handlerMap，来调用客户端所请求的业务方法<br>并将业务方法返回值封装成response对象写入下一个handler（即编码handler—— RpcEncoder）<br> RpcServer<br>框架的RPC 服务器（用于将用户系统的业务类发布为 RPC 服务）<br>使用时可由用户通过spring-bean的方式注入到用户的业务系统中<br>由于本类实现了ApplicationContextAware InitializingBeans，spring构造本对象时会调用setApplicationContext()方法，从而可以在方法中通过自定义注解获得用户的业务接口和实现，还会调用afterPropertiesSet()方法，在方法中启动netty服务器<br>RpcService<br>RPC 请求注解（标注在服务实现类上</p>
<h4 id="3-rpc-registry模块"><a href="#3-rpc-registry模块" class="headerlink" title="3.   rpc-registry模块"></a>3.   rpc-registry模块</h4><p> Constant<br> zookeeper 常量<br> ServiceDiscovery<br>用于client发现server节点的变化 ，实现负载均衡）<br>ServiceRegistry<br>服务注册 ，ZK 在该架构中扮演了“服务注册表”的角色，用于注册所有服务器的地址与端口，并对客户端提供服务发现的功能</p>
<h4 id="4-rpc-common-server模块"><a href="#4-rpc-common-server模块" class="headerlink" title="4.  rpc-common-server模块"></a>4.  rpc-common-server模块</h4><p>RpcDecoder<br>解码器<br>RpcEncoder<br>编码器<br>RpcRequest<br>封装 RPC 请求 ，封装发送的object的反射属性<br>RpcResponse<br>封装 RPC 响应 ，封装相应object<br>SerializationUtil<br>基于  Protostuff  实现的序列化工具类</p>
<h4 id="5-rpc-common-interfaces模块"><a href="#5-rpc-common-interfaces模块" class="headerlink" title="5. rpc-common-interfaces模块"></a>5. rpc-common-interfaces模块</h4><p>Entity<br>封装的通信实体对象类<br>HelloService<br>客户端调用的接口类</p>
<h3 id="rpc-客户端"><a href="#rpc-客户端" class="headerlink" title="rpc-客户端"></a>rpc-客户端</h3><h4 id="1-rpc-sample-client模块"><a href="#1-rpc-sample-client模块" class="headerlink" title="1.  rpc-sample-client模块"></a>1.  rpc-sample-client模块</h4><p>HelloActionTest<br>客户端发起调用的Action类</p>
<h4 id="2-rpc-client模块"><a href="#2-rpc-client模块" class="headerlink" title="2.  rpc-client模块"></a>2.  rpc-client模块</h4><p>RpcClient<br>框架的RPC 客户端（用于发送 RPC 请求）<br>RpcProxy<br>RPC 代理（用于创建 RPC 服务代理）</p>
<h4 id="3-rpc-registry模块-1"><a href="#3-rpc-registry模块-1" class="headerlink" title="3. rpc-registry模块"></a>3. rpc-registry模块</h4><p>客户端注册zk服务，同Server端</p>
<h4 id="4-rpc-common-client模块"><a href="#4-rpc-common-client模块" class="headerlink" title="4.  rpc-common-client模块"></a>4.  rpc-common-client模块</h4><p>工具类，同Server端</p>
<h4 id="5-rpc-common-interface模块"><a href="#5-rpc-common-interface模块" class="headerlink" title="5.  rpc-common-interface模块"></a>5.  rpc-common-interface模块</h4><p>接口类与实体类，同Server端</p>
</blockquote>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[轻量级RPC框架（一）]]></title>
      <url>http://spark8.tech/2016/05/12/easyrpc/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="一、RPC原理"><a href="#一、RPC原理" class="headerlink" title="一、RPC原理"></a>一、RPC原理</h2><ol>
<li><p>消息框架MQ与RPC框架区别<br>RPC（Remote Procedure Call Protocol）是面向动作的，请求响应模式。多用于系统Action层和Service层通信，缓解服务端多线程并发压力。<br>技术组成包括 NIO+序列化+反射+动态代理<br>MQ 是面向数据的，生产者消费者模式，多用于不同系统间的数据传送，面向多订阅用户的消息推送，NIO+序列化+JMS</p>
</li>
<li><p>什么是RPC<br>RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易。<br>RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。</p>
</li>
<li>RPC调用过程<br><img src="/images/RPC结构.png" alt="RPC调用过程" title="RPC调用过程"><h2 id="二、NIO原理"><a href="#二、NIO原理" class="headerlink" title="二、NIO原理"></a>二、NIO原理</h2><h3 id="socket-NIO原理"><a href="#socket-NIO原理" class="headerlink" title="socket NIO原理"></a>socket NIO原理</h3></li>
<li>同步与异步，阻塞和非阻塞<br>同步与异步关注的是 消息通信机制<br>同步和异步都是基于应用程序和操作系统处理IO事件所采用的方式<br>阻塞和非阻塞是进程在访问数据的时候，数据是否准备就绪的一种处理方式。<br>阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态<br><a href="https://www.zhihu.com/question/19732473" target="_blank" rel="external">知乎链接</a></li>
<li>NIO原理解读<br>对于网络通信而言，NIO  AIO并没有改变网络通信的基本步骤，只是在原来的基础上（serversocket，socket）做了一个改进。<br><img src="/images/NIO与传统IO.png" alt="NIO与传统IO" title="NIO与传统IO"></li>
</ol>
<h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><p>1）BIO阻塞的IO<br>2）NIO select多路复用+非阻塞   同步非阻塞<br>3）AIO异步非阻塞IO</p>
<h2 id="三、netty框架"><a href="#三、netty框架" class="headerlink" title="三、netty框架"></a>三、netty框架</h2><p>使用实例见<a href="github.com/sparkliwei">github链接</a><br>总结：在使用Handler的过程中，需要注意：<br>1、ChannelInboundHandler之间的传递，通过调用 ctx.fireChannelRead(msg) 实现；调用ctx.write(msg) 将传递到ChannelOutboundHandler。<br>2、ctx.write()方法执行后，需要调用flush()方法才能令它立即执行。<br>3、流水线pipeline中outhandler不能放在最后，否则不生效</p>
<p>如果使用addlast方法来组装handler，则为以下执行顺序：<br>// 注册两个InboundHandler，执行顺序为注册顺序，所以应该是InboundHandler1 InboundHandler2<br>// 注册两个OutboundHandler，执行顺序为注册顺序的逆序，所以应该是OutboundHandler2 OutboundHandler1</p>
<h2 id="四、反射"><a href="#四、反射" class="headerlink" title="四、反射"></a>四、反射</h2><p>常见的是json或字符串文本转换成java对象，见以下实例,此处RPC框架开发中用Spring代替<br>        public class MyReflect {<br>            public String className = null;<br>            @SuppressWarnings(“rawtypes”)<br>            // Class 代表JVM中加载好的一个特定class文件<br>            public Class personClass = null;<br>            /**</p>
<pre><code>     * 反射Person类
     * @throws Exception 
     */
    @Before
    public void init() throws Exception {
        className = &quot;day04.cn.holley_04_reflect.Person&quot;;
        // 通过Class.forName( 类全路径字符串)，就能将这个类的class文件加载到JVM内存中
        personClass = Class.forName(className);
    }
    /**
     *获取某个class文件对象
     */
    @Test
    public void getClassName() throws Exception {
        System.out.println(personClass);
    }
    /**
     *获取某个class文件对象的另一种方式
     */
    @Test
    public void getClassName2() throws Exception {
        System.out.println(Person.class);
    }
    /**
     *创建一个class文件表示的实例对象，底层会调用空参数的构造方法
     */
    @Test
    public void getNewInstance() throws Exception {
        System.out.println(personClass.newInstance());
    }
    /**
     *获取非私有的构造函数
     */
    @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })
    @Test
    public void getPublicConstructor() throws Exception {
        Constructor  constructor  = personClass.getConstructor(Long.class,String.class);
        Person person = (Person)constructor.newInstance(100L,&quot;zhangsan&quot;);
        System.out.println(person.getId());
        System.out.println(person.getName());
    }
    /**
     *获得私有的构造函数
     */
    @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })
    @Test
    public void getPrivateConstructor() throws Exception {
        Constructor con = personClass.getDeclaredConstructor(String.class);
        con.setAccessible(true);//强制取消Java的权限检测
        Person person2 = (Person)con.newInstance(&quot;zhangsan&quot;);
        System.out.println(&quot;**&quot;+person2.getName());
    }
    /**
     *访问非私有的成员变量
     */
    @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })
    @Test
    public void getNotPrivateField() throws Exception {
        Constructor  constructor  = personClass.getConstructor(Long.class,String.class);
        Object obj = constructor.newInstance(100L,&quot;zhangsan&quot;);

        Field field = personClass.getField(&quot;name&quot;);
        field.set(obj, &quot;lisi&quot;);
        System.out.println(field.get(obj));
    }
    /**
     *访问私有的成员变量
     */
    @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })
    @Test
    public void getPrivateField() throws Exception {
        Constructor  constructor  = personClass.getConstructor(Long.class);
        Object obj = constructor.newInstance(100L);

        Field field2 = personClass.getDeclaredField(&quot;id&quot;);
        field2.setAccessible(true);//强制取消Java的权限检测
        field2.set(obj,10000L);
        System.out.println(field2.get(obj));
    }
    /**
     *获取非私有的成员函数
     */
    @SuppressWarnings({ &quot;unchecked&quot; })
    @Test
    public void getNotPrivateMethod() throws Exception {
        System.out.println(personClass.getMethod(&quot;toString&quot;));

        Object obj = personClass.newInstance();//获取空参的构造函数
        Method toStringMethod = personClass.getMethod(&quot;toString&quot;);
        Object object = toStringMethod.invoke(obj);
        System.out.println(object);
    }
    /**
     *获取私有的成员函数
     */
    @SuppressWarnings(&quot;unchecked&quot;)
    @Test
    public void getPrivateMethod() throws Exception {
        Object obj = personClass.newInstance();//获取空参的构造函数
        Method method = personClass.getDeclaredMethod(&quot;getSomeThing&quot;);
        method.setAccessible(true);
        Object value = method.invoke(obj);
        System.out.println(value);

    }
    /**
     *
     */
    @Test
    public void otherMethod() throws Exception {
        //当前加载这个class文件的那个类加载器对象
        System.out.println(personClass.getClassLoader());
        //获取某个类实现的所有接口
        Class[] interfaces = personClass.getInterfaces();
        for (Class class1 : interfaces) {
            System.out.println(class1);
        }
        //反射当前这个类的直接父类
        System.out.println(personClass.getGenericSuperclass());
        /**
         * getResourceAsStream这个方法可以获取到一个输入流，这个输入流会关联到name所表示的那个文件上。
         */
        //path 不以’/&apos;开头时默认是从此类所在的包下取资源，以’/&apos;开头则是从ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。
        System.out.println(personClass.getResourceAsStream(&quot;/log4j.properties&quot;));
        System.out.println(personClass.getResourceAsStream(&quot;log4j.properties&quot;));

        //判断当前的Class对象表示是否是数组
        System.out.println(personClass.isArray());
        System.out.println(new String[3].getClass().isArray());

        //判断当前的Class对象表示是否是枚举类
        System.out.println(personClass.isEnum());
        System.out.println(Class.forName(&quot;day04.cn.holley_04_reflect.City&quot;).isEnum());

        //判断当前的Class对象表示是否是接口
        System.out.println(personClass.isInterface());
        System.out.println(Class.forName(&quot;day04.cn.holley_04_reflect.TestInterface&quot;).isInterface());


    }

}
</code></pre><h2 id="五、动态代理"><a href="#五、动态代理" class="headerlink" title="五、动态代理"></a>五、动态代理</h2><h3 id="动态代理：在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。"><a href="#动态代理：在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。" class="headerlink" title="动态代理：在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。"></a>动态代理：在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。</h3><h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><ol>
<li>旧业务<br>买家调用action，购买衣服，衣服在数据库的标价为50元，购买流程就是简单的调用。</li>
<li>新业务<br>在原先的价格上可以使用优惠券，但是这个功能在以前没有实现过，我们通过代理类，代理了原先的接口方法，在这个方法的基础上，修改了返回值。<br><img src="/images/动态代理proxy.png" alt="动态代理" title="动态代理"><h3 id="实现流程："><a href="#实现流程：" class="headerlink" title="实现流程："></a>实现流程：</h3></li>
<li>书写代理类和代理方法，在代理方法中实现代理Proxy.newProxyInstance</li>
<li>代理中需要的参数分别为：被代理的类的类加载器soneObjectclass.getClassLoader()，被代理类的所有实现接口new Class<a href="#"></a>  Interface.class ，句柄方法new InvocationHandler()</li>
<li>在句柄方法中复写invoke方法，invoke方法的输入有3个参数Object proxy（代理类对象）, Method method（被代理类的方法）,Object<a href="#"></a> args（被代理类方法的传入参数），在这个方法中，我们可以定制化的开发新的业务。</li>
<li><p>获取代理类，强转成被代理的接口<br>最后，我们可以像没被代理一样，调用接口的认可方法，方法被调用后，方法名和参数列表将被传入代理类的invoke方法中，进行新业务的逻辑流程。<br>核心代码：</p>
<pre><code>ProxySaleAction
    /**
     * 什么是动态代理？ 简单的写一个模板接口，剩下的个性化工作，好给动态代理来完成！
     */
    public class ProxySaleAction {

        /**
         *使用代理，在这个代理中，只代理了Boss的yifu方法
         *定制化业务，可以改变原接口的参数、返回值等
         */
        @Test
        public void saleByProxy() throws Exception {
            IBoss boss = ProxyBoss.getProxy(10, IBoss.class, Boss.class);// 将代理的方法实例化成接口
            //IBoss boss = new Boss();// 将代理的方法实例化成接口
            System.out.println(&quot;代理经营！&quot;);

            int money = boss.yifu(&quot;xxl&quot;);// 调用接口的方法，实际上调用方式没有变
            System.out.println(&quot;衣服成交价：&quot; + money);
        }
    }
SaleAction
    public class SaleAction {
        /**
         * 不使用代理，直接调用方法
         * 方法中规定什么业务，就只能调用什么业务，规定什么返回值，就只能输出什么返回值
         */
        @Test
        public void saleByBossSelf() throws Exception {
            IBoss boss = new Boss();
            System.out.println(&quot;老板自营！&quot;);
            int money = boss.yifu(&quot;xxl&quot;);// 老板自己卖衣服，不需要客服，结果就是没有聊天记录
            System.out.println(&quot;衣服成交价：&quot; + money);
        }
    }
ProxyBoss
    public class ProxyBoss {
        /**
         * 对接口方法进行代理
         */
        @SuppressWarnings(&quot;unchecked&quot;)
        public static &lt;T&gt; T getProxy(final int discountCoupon,
                final Class&lt;?&gt; interfaceClass, final Class&lt;?&gt; implementsClass)
                throws Exception {
            return (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(),
                    new Class[] { interfaceClass }, new InvocationHandler() {
                        public Object invoke(Object proxy, Method method,
                                Object[] args) throws Throwable {
                            Integer returnValue = (Integer) method.invoke(
                                    implementsClass.newInstance(), args);// 调用原始对象以后返回的值
                            return returnValue - discountCoupon;
                        }
                    });
        }
    }
</code></pre></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[推荐系统——User CF vs. Item CF]]></title>
      <url>http://spark8.tech/2016/04/12/tjxt/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h1 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a>计算复杂度</h1><p>Item CF 和 User CF 是基于协同过滤推荐的两个最基本的算法，User CF 是很早以前就提出来了，Item CF 是从 Amazon 的论文和专利发表之后（2001 年左右）开始流行，大家都觉得 Item CF 从性能和复杂度上比 User CF 更优，<strong>其中的一个主要原因就是对于一个在线网站，用户的数量往往大大超过物品的数量，同时物品的数据相对稳定，因此计算物品的相似度不但计算量较小，同时 也不必频繁更新。但我们往往忽略了这种情况只适应于提供商品的电子商务网站，对于新闻，博客或者微内容的推荐系统，情况往往是相反的，物品的数量是海量 的，同时也是更新频繁的，所以单从复杂度的角度，这两个算法在不同的系统中各有优势，推荐引擎的设计者需要根据自己应用的特点选择更加合适的算法。</strong></p>
<h1 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h1><p>在非社交网络的网站中，内容内在的联系是很重要的推荐原则，它比基于相似用户的推荐原则更加有效。比如在购书网站上，当你看一本书的时候，推荐引擎 会给你推荐相关的书籍，这个推荐的重要性远远超过了网站首页对该用户的综合推荐。可以看到，在这种情况下，Item CF 的推荐成为了引导用户浏览的重要手段。同时 Item CF 便于为推荐做出解释，在一个非社交网络的网站中，给某个用户推荐一本书，同时给出的解释是某某和你有相似兴趣的人也看了这本书，这很难让用户信服，因为用 户可能根本不认识那个人；但如果解释说是因为这本书和你以前看的某本书相似，用户可能就觉得合理而采纳了此推荐。相反的，在现今很流行的社交网络站点中，User CF 是一个更不错的选择，User CF 加上社会网络信息，可以增加用户对推荐解释的信服程度。</p>
<h1 id="推荐多样性和精度"><a href="#推荐多样性和精度" class="headerlink" title="推荐多样性和精度"></a>推荐多样性和精度</h1><p>研究推荐引擎的学者们在相同的数据集合上分别用 User CF 和 Item CF 计算推荐结果，发现推荐列表中，只有 50% 是一样的，还有 50% 完全不同。但是这两个算法确有相似的精度，所以可以说，这两个算法是很互补的。<br>关于推荐的多样性，有两种度量方法：<br>第一种度量方法是从单个用户的角度度量，就是说给定一个用户，查看系统给出的推荐列表是否多样，也就是要比较推荐列表中的物品之间两两的相似度，不 难想到，对这种度量方法，Item CF 的多样性显然不如 User CF 的好，因为 Item CF 的推荐就是和以前看的东西最相似的。<br>第二种度量方法是考虑系统的多样性，也被称为覆盖率 (Coverage)，它是指一个推荐系统是否能够提供给所有用户丰富的选择。在这种指标下，Item CF 的多样性要远远好于 User CF, 因为 User CF 总是倾向于推荐热门的，从另一个侧面看，也就是说，Item CF 的推荐有很好的新颖性，很擅长推荐长尾里的物品。所以，尽管大多数情况，Item CF 的精度略小于 User CF， 但如果考虑多样性，Item CF 却比 User CF 好很多。<br>如果你对推荐的多样性还心存疑惑，那么下面我们再举个实例看看 User CF 和 Item CF 的多样性到底有什么差别。<br>首先，假设每个用户兴趣爱好都是广泛的，喜欢好几个领域的东西，不过每个用户肯定也有一个主要的领域，对这个领域会比其他领域更加关心。<br>给定一个用户，假设他喜欢 3 个领域 A,B,C，A 是他喜欢的主要领域，这个时候我们来看 User CF 和 Item CF 倾向于做出什么推荐：如果用 User CF, 它会将 A,B,C 三个领域中比较热门的东西推荐给用户；而如果用 ItemCF，它会基本上只推荐 A 领域的东西给用户。所以我们看到因为 User CF 只推荐热门的，所以它在推荐长尾里项目方面的能力不足；而 Item CF 只推荐 A 领域给用户，这样他有限的推荐列表中就可能包含了一定数量的不热门的长尾物品，同时 Item CF 的推荐对这个用户而言，显然多样性不足。但是对整个系统而言，因为不同的用户的主要兴趣点不同，所以系统的覆盖率会比较好。<br>从上面的分析，可以很清晰的看到，这两种推荐都有其合理性，但都不是最好的选择，因此他们的精度也会有损失。其实对这类系统的最好选择是，如果系统 给这个用户推荐 30 个物品，既不是每个领域挑选 10 个最热门的给他，也不是推荐 30 个 A 领域的给他，而是比如推荐 15 个 A 领域的给他，剩下的 15 个从 B,C 中选择。所以结合 User CF 和 Item CF 是最优的选择，结合的基本原则就是当采用 Item CF 导致系统对个人推荐的多样性不足时，我们通过加入 User CF 增加个人推荐的多样性，从而提高精度，而当因为采用 User CF 而使系统的整体多样性不足时，我们可以通过加入 Item CF 增加整体的多样性，同样同样可以提高推荐的精度。</p>
<h1 id="用户对推荐算法的适应度"><a href="#用户对推荐算法的适应度" class="headerlink" title="用户对推荐算法的适应度"></a>用户对推荐算法的适应度</h1><p>前面我们大部分都是从推荐引擎的角度考虑哪个算法更优，但其实我们更多的应该考虑作为推荐引擎的最终使用者 – 应用用户对推荐算法的适应度。<br>对于 User CF，推荐的原则是假设用户会喜欢那些和他有相同喜好的用户喜欢的东西，但如果一个用户没有相同喜好的朋友，那 User CF 的算法的效果就会很差，所以一个用户对的 CF 算法的适应度是和他有多少共同喜好用户成正比的。<br>Item CF 算法也有一个基本假设，就是用户会喜欢和他以前喜欢的东西相似的东西，那么我们可以计算一个用户喜欢的物品的自相似度。一个用户喜欢物品的自相似度大，就 说明他喜欢的东西都是比较相似的，也就是说他比较符合 Item CF 方法的基本假设，那么他对 Item CF 的适应度自然比较好；反之，如果自相似度小，就说明这个用户的喜好习惯并不满足 Item CF 方法的基本假设，那么对于这种用户，用 Item CF 方法做出好的推荐的可能性非常低。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Redis应用-LOL盒子英雄数据排行榜]]></title>
      <url>http://spark8.tech/2016/03/14/redis_sortedSet/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><p>按出场次数多少快速计算LOL中英雄排行榜</p>
<h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><ol>
<li>在redis中需要一个榜单所对应的sortedset数据</li>
<li>玩家每选择一个英雄打一场游戏，就对sortedset数据的相应的英雄分数+1</li>
<li>Lol盒子上查看榜单时，就调用zrange来看榜单中的排序结果<h2 id="代码开发"><a href="#代码开发" class="headerlink" title="代码开发"></a>代码开发</h2></li>
<li><p>LolBoxPlayer</p>
<pre><code>public class LolBoxPlayer {
    public static void main(String[] args) throws Exception {

        Jedis jedis = new Jedis(&quot;192.168.59.101&quot;, 6379);

        Random random = new Random();
        String[] heros = {&quot;易大师&quot;,&quot;德邦&quot;,&quot;剑姬&quot;,&quot;盖伦&quot;,&quot;阿卡丽&quot;,&quot;金克斯&quot;,&quot;提莫&quot;,&quot;猴子&quot;,&quot;亚索&quot;};
        while(true){

            int index = random.nextInt(heros.length);
            //选择一个英雄
            String hero = heros[index];

            //开始玩游戏
            Thread.sleep(1000);

            //给集合中的该英雄的出场次数加1
            //第一次添加的时候，集合不存在，zincrby方法会创建
            jedis.zincrby(&quot;hero:ccl:phb&quot;, 1, hero);

            System.out.println(hero+&quot; 出场了.......&quot;);
        }
    }
}
</code></pre></li>
<li><p>LolBoxViewer</p>
<pre><code>/**
 * 英雄出场率排行榜查看模块
 * 
 * @author
 * 
 */
public class LolBoxViewer {
    public static void main(String[] args) throws Exception {
        Jedis jedis = new Jedis(&quot;192.168.59.101&quot;, 6379);
        int i = 1;
        while (true) {
            // 每隔3秒查看一次榜单
            Thread.sleep(3000);

            System.out.println(&quot;第&quot; + i + &quot;次查看榜单-----------&quot;);

            // 从redis中查询榜单的前N名
            Set&lt;Tuple&gt; topHeros = jedis.zrevrangeWithScores(&quot;hero:ccl:phb&quot;, 0, 4);

            for (Tuple t : topHeros) {

                System.out.println(t.getElement() + &quot;   &quot; + t.getScore());
            }
            i++;
            System.out.println(&quot;&quot;);
            System.out.println(&quot;&quot;);
            System.out.println(&quot;&quot;);
        }
    }
}
</code></pre></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Redis应用-购物车推荐]]></title>
      <url>http://spark8.tech/2016/03/12/redisgouwuche/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>根据历史用户的购物车数据，对新用户的购物车做一个推荐</p>
<h1 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h1><ol>
<li>每来一个用户创建购物车，就对购物车中的每一件商品在redis中插入一条以商品名称为key的sortedset，成员为同时出现在购物车中的其他商品，分数为1</li>
<li>每新产生一个购物车，就对车中的商品更新redis中的sortedset，将同时出现的商品的分数增1</li>
<li><p>推荐时，用户放入一件商品到购物车，则从这件商品对应的sortedset中查询分数最高的同件商品，推荐给该用户<br><img src="/images/gouwuche.png" alt="redis实现购物车" title="redis实现购物车"></p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>核心代码RedisServer如下，完整项目请参见<a href="github.com/sparkliwei">github链接</a></p>
<pre><code>public class RedisService {

Jedis jedis = new Jedis(GlobalInstants.REDIS_SERVER, 6379);

/**
 * 将用户选择的商品添加到购物车 同时，将购物车信息添加到推荐池
 *
 * @param userName
 * @param newItem
 */
public void addToCart(String userName, String newItem, int incr) {

    //如果该用户的购物车中已经存在该商品，那么就不需要做推荐池数据的生成或更新
    if (!jedis.hexists(GlobalInstants.CART_PREFIX + userName, newItem)) {
        // 首先从该用户的购物车中将已经存在的商品取出来
        Set&lt;String&gt; oldItems = getCartItems(userName);   // oldItems : a b
        oldItems.remove(newItem);

        for (String oldItem : oldItems) {

            //为新商品创建一个推荐池，将每一个老商品添加进去
            jedis.zincrby(GlobalInstants.ITEM_RECOMMEND_POOL + newItem, 1, oldItem);
            //为每一个老商品的推荐池添加该新商品
            jedis.zincrby(GlobalInstants.ITEM_RECOMMEND_POOL + oldItem, 1, newItem);

        }

    }
    // 往购物车中添加商品及数量，购物车存放的数据结构为hash
    jedis.hincrBy(GlobalInstants.CART_PREFIX + userName, newItem, incr);

}

/**
 * 从redis中取出用户购物车中的商品及数量
 *
 * @param userName
 * @return
 */
public Map&lt;String, String&gt; getCart(String userName) {

    Map&lt;String, String&gt; itemAndNumb = jedis.hgetAll(GlobalInstants.CART_PREFIX + userName);

    return itemAndNumb;
}

/**
 * 查询购物车中的商品项
 *
 * @param userName
 * @return
 */
public Set&lt;String&gt; getCartItems(String userName) {

    Set&lt;String&gt; items = jedis.hkeys(GlobalInstants.CART_PREFIX + userName);

    return items;
}

/**
 * 根据给定的用户根据其购物车中的商品项推荐其他商品
 *
 * @param userName
 * @return
 */
public Map&lt;String, Double&gt; recommend(String userName) {

    //先拿到该用户当前购物车中所有的商品项
    Set&lt;String&gt; cartItems = getCartItems(userName);
    for (String item : cartItems) {
        // 将每一个商品项的推荐项添加到redis中的总推荐表
        // 合并sortedset的过程中，redis会自动将相同商品的推荐得分累加
        jedis.zunionstore(GlobalInstants.USER_RECOMMEND_POOL + userName, GlobalInstants.ITEM_RECOMMEND_POOL + item);

    }

    //从总推荐池去除用户购物车中已有的商品项
    jedis.zrem(GlobalInstants.USER_RECOMMEND_POOL + userName, cartItems.toString());

    //取出redis中的用户总推荐表中的前4名推荐商品
    Set&lt;Tuple&gt; recommends = jedis.zrevrangeWithScores(GlobalInstants.USER_RECOMMEND_POOL + userName, 0, 3);

    //将从redis中获取到的前4名推荐商品的名称及推荐得分封装到hashmap中返回给action
    HashMap&lt;String, Double&gt; recommendsMap = new HashMap&lt;String, Double&gt;();
    for (Tuple t : recommends) {
        recommendsMap.put(t.getElement(), t.getScore());
    }
    return recommendsMap;
}
}
</code></pre></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Zookeeper-分布式共享锁]]></title>
      <url>http://spark8.tech/2016/03/11/zkfbss/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<h2 id="一、需求描述"><a href="#一、需求描述" class="headerlink" title="一、需求描述"></a>一、需求描述</h2><p>  在我们自己的分布式业务系统中，可能会存在某种资源，需要被整个系统的各台服务器共享访问，但是只允许一台服务器同时访问</p>
<h2 id="二、设计思路"><a href="#二、设计思路" class="headerlink" title="二、设计思路"></a>二、设计思路</h2><ol>
<li>连接zookeeper，process监听子节点变化事件，接收事件按规则写业务逻辑，并重新注册锁</li>
<li>向zookeeper注册一把锁</li>
<li>从zk的锁父目录下，获取所有子节点，并且注册对父节点的监听</li>
<li>如果争抢资源的程序就只有自己，则可以直接去访问共享资源</li>
<li>访问资源后删除锁<h2 id="三、代码开发"><a href="#三、代码开发" class="headerlink" title="三、代码开发"></a>三、代码开发</h2>   public class DistributedClientLock {</li>
</ol>
<pre><code>       // 会话超时
       private static final int SESSION_TIMEOUT = 2000;
       // zookeeper集群地址
       private String hosts = &quot;mini1:2181,mini2:2181,mini3:2181&quot;;
       private String groupNode = &quot;locks&quot;;
       private String subNode = &quot;sub&quot;;
       private boolean haveLock = false;

       private ZooKeeper zk;
       // 记录自己创建的子节点路径
       private volatile String thisPath;

       /**
        * 连接zookeeper
        */
       public void connectZookeeper() throws Exception {
           zk = new ZooKeeper(hosts, SESSION_TIMEOUT, new Watcher() {
               public void process(WatchedEvent event) {
                   try {

                       // 判断事件类型，此处只处理子节点变化事件
                       if (event.getType() == EventType.NodeChildrenChanged &amp;&amp; event.getPath().equals(&quot;/&quot; + groupNode)) {
                           //获取子节点，并对父节点进行监听
                           List&lt;String&gt; childrenNodes = zk.getChildren(&quot;/&quot; + groupNode, true);
                           String thisNode = thisPath.substring((&quot;/&quot; + groupNode + &quot;/&quot;).length());
                           // 去比较是否自己是最小id
                           Collections.sort(childrenNodes);
                           if (childrenNodes.indexOf(thisNode) == 0) {
                               //访问共享资源处理业务，并且在处理完成之后删除锁
                               doSomething();

                               //重新注册一把新的锁
                               thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE,
                                       CreateMode.EPHEMERAL_SEQUENTIAL);
                           }
                       }
                   } catch (Exception e) {
                       e.printStackTrace();
                   }
               }
           });

           // 1、程序一进来就先注册一把锁到zk上
           thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE,
                   CreateMode.EPHEMERAL_SEQUENTIAL);

           // wait一小会，便于观察
           Thread.sleep(new Random().nextInt(1000));

           // 从zk的锁父目录下，获取所有子节点，并且注册对父节点的监听
           List&lt;String&gt; childrenNodes = zk.getChildren(&quot;/&quot; + groupNode, true);

           // 如果争抢资源的程序就只有自己，则可以直接去访问共享资源 
           if (childrenNodes.size() == 1) {
               doSomething();
               thisPath = zk.create(&quot;/&quot; + groupNode + &quot;/&quot; + subNode, null, Ids.OPEN_ACL_UNSAFE,
                       CreateMode.EPHEMERAL_SEQUENTIAL);
           }
       }

       /**
        * 处理业务逻辑，并且在最后释放锁
        */
       private void doSomething() throws Exception {
           try {
               System.out.println(&quot;gain lock: &quot; + thisPath);
               Thread.sleep(2000);
               // do something
           } finally {
               System.out.println(&quot;finished: &quot; + thisPath);
       //删除之前的锁节点
               zk.delete(this.thisPath, -1);
           }
       }

       public static void main(String[] args) throws Exception {
           DistributedClientLock dl = new DistributedClientLock();
           dl.connectZookeeper();
           Thread.sleep(Long.MAX_VALUE);
       }


}
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Zookeeper-服务器上下线动态感知]]></title>
      <url>http://spark8.tech/2016/03/11/zkfbs/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<p>Zookeeper是一个分布式协调服务<br>在底层其实只提供了两个功能：<br><em>a、管理(存储，读取)用户程序提交的数据；PERSISTANT持久节点</em><br><em>b、并为用户程序提供数据节点监听服务； Ephemeral节点</em></p>
<h2 id="一、需求描述"><a href="#一、需求描述" class="headerlink" title="一、需求描述"></a>一、需求描述</h2><p>某分布式系统中，主节点可以有多台，可以动态上下线<br>任意一台客户端都能实时感知到主节点服务器的上下线</p>
<h2 id="二、设计思路"><a href="#二、设计思路" class="headerlink" title="二、设计思路"></a>二、设计思路</h2><p><img src="/images/zkfbs.png" alt="分布式共享锁" title="分布式共享锁"></p>
<h2 id="三、代码开发"><a href="#三、代码开发" class="headerlink" title="三、代码开发"></a>三、代码开发</h2><h3 id="1-客户端实现"><a href="#1-客户端实现" class="headerlink" title="1. 客户端实现"></a>1. 客户端实现</h3><pre><code>  public class DistributedClient {
      private static final String connectString = &quot;mini1:2181,mini2:2181,mini3:2181&quot;;
      private static final int sessionTimeout = 2000;
      private static final String parentNode = &quot;/servers&quot;;
      // 注意:加volatile的意义何在？先写再读，保证读的结果一致
      private volatile List&lt;String&gt; serverList;
      private ZooKeeper zk = null;

      /**
       * 创建到zk的客户端连接
       * 
       * @throws Exception
       */
      public void getConnect() throws Exception {
          zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {
              public void process(WatchedEvent event) {
              // 收到事件通知后的回调函数（应该是我们自己的事件处理逻辑）
                  try {
                      //重新更新服务器列表，并且注册了监听
                      getServerList();
                  } catch (Exception e) {
                  }
              }
              });
      }

      /**
       * 获取服务器信息列表
       * 
       * @throws Exception
       */
      public void getServerList() throws Exception {
          // 获取服务器子节点信息，并且对父节点进行监听
          List&lt;String&gt; children = zk.getChildren(parentNode, true);

          // 先创建一个局部的list来存服务器信息
          List&lt;String&gt; servers = new ArrayList&lt;String&gt;();
          for (String child : children) {
              // child只是子节点的节点名
              byte[] data = zk.getData(parentNode + &quot;/&quot; + child, false, null);
              servers.add(new String(data));
          }
          // 把servers赋值给成员变量serverList，已提供给各业务线程使用
          serverList = servers;

          //打印服务器列表
          System.out.println(serverList);
      }

      /**
       * 业务功能
       * @throws InterruptedException
       */
      public void handleBussiness() throws InterruptedException {
          System.out.println(&quot;client start working.....&quot;);
          Thread.sleep(Long.MAX_VALUE);
      }

      public static void main(String[] args) throws Exception {
          // 获取zk连接
          DistributedClient client = new DistributedClient();
          client.getConnect();
          // 获取servers的子节点信息（并监听），从中获取服务器信息列表
          client.getServerList();
          // 业务线程启动
          client.handleBussiness();
      }
}
</code></pre><h3 id="2-服务端实现"><a href="#2-服务端实现" class="headerlink" title="2. 服务端实现"></a>2. 服务端实现</h3><pre><code>  public class DistributedServer {

    private static final String CONNECT_STRING   = &quot;mini1:2181,mini2:2181,mini3:2181&quot;;
    private static final int    SESSION_TIME_OUT = 2000;
    private static final String PARENT_NODE      = &quot;/servers&quot;;

    private ZooKeeper zk = null;

    /**
     * 创建到zk的客户端连接
     *
     * @throws Exception
     */
    public void getConnect() throws Exception {

        zk = new ZooKeeper(CONNECT_STRING, SESSION_TIME_OUT, new Watcher() {
            public void process(WatchedEvent event) {
                // 收到事件通知后的回调函数（应该是我们自己的事件处理逻辑）
                System.out.println(event.getType() + &quot;---&quot; + event.getPath());
                /*try {
            zk.getChildren(&quot;/&quot;, true);
        } catch (Exception e) {
        }*/
            }
        });
    }

    /**
     * 向zk集群注册服务器信息
     * @param hostname
     * @throws Exception
     */
    public void registerServer(String hostname) throws Exception {
        Stat exists = zk.exists(PARENT_NODE, false);
        if (exists == null) zk.create(PARENT_NODE, null, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        String path = zk.create(PARENT_NODE + &quot;/server&quot;, hostname.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
        System.out.println(hostname + &quot;is online..&quot; + path);
    }

    /**
     * 业务功能
     * @throws InterruptedException
     */
    public void handleBussiness(String hostname) throws InterruptedException {
        System.out.println(hostname + &quot;start working.....&quot;);
        Thread.sleep(Long.MAX_VALUE);
    }

    public static void main(String[] args) throws Exception {

        DistributedServer server = new DistributedServer();
        // 获取zk连接
        server.getConnect();

        // 利用zk连接注册服务器信息(主机名)
        server.registerServer(args[0]);

        // 启动业务功能
        server.handleBussiness(args[0]);
    }
}
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Zookeeper-原理补充]]></title>
      <url>http://spark8.tech/2016/03/11/zkyuanli/</url>
      <content type="html"><![CDATA[<p>\&lt;!–more–></p>
<h2 id="Zookepper的选举机制（保证数据一致性的核心算法paxos）"><a href="#Zookepper的选举机制（保证数据一致性的核心算法paxos）" class="headerlink" title="Zookepper的选举机制（保证数据一致性的核心算法paxos）"></a>Zookepper的选举机制（保证数据一致性的核心算法paxos）</h2><p>以一个简单的例子来说明整个选举的过程.<br>假设有五台服务器组成的zookeeper集群,它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动,来看看会发生什么.<br>1) 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态<br>2) 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态.<br>3) 服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的leader.<br>4) 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了.<br>5) 服务器5启动,同4一样,当小弟.</p>
<h2 id="非全新集群的选举机制-数据恢复"><a href="#非全新集群的选举机制-数据恢复" class="headerlink" title="非全新集群的选举机制(数据恢复)"></a>非全新集群的选举机制(数据恢复)</h2><p>那么，初始化的时候，是按照上述的说明进行选举的，但是当zookeeper运行了一段时间之后，有机器down掉，重新选举时，选举过程就相对复杂了。<br>需要加入数据version、leader id和逻辑时钟。<br>数据version：数据新的version就大，数据每次更新都会更新version。<br>Leader id：就是我们配置的myid中的值，每个机器一个。<br>逻辑时钟：这个值从0开始递增,每次选举对应一个值,也就是说:  如果在同一次选举中,那么这个值应该是一致的 ;  逻辑时钟值越大,说明这一次选举leader的进程更新.<br>选举的标准就变成：<br>1、逻辑时钟小的选举结果被忽略，重新投票<br>2、统一逻辑时钟后，数据id大的胜出<br>3、数据id相同的情况下，leader id大的胜出<br>根据这个规则选出leader。</p>
]]></content>
    </entry>
    
  
  
</search>
